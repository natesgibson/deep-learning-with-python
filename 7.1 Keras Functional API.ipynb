{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-input Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build multi-input model (to predict 1-word answer from relevant background text and a user question)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "text_vocab_size = 10_000\n",
    "question_vocab_size = 10_000\n",
    "answer_vocab_size = 500\n",
    "\n",
    "# input 1\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')\n",
    "embedded_text = layers.Embedding(text_vocab_size, 64)(text_input) # the embedding arguments are backwards in the text\n",
    "encoded_text = layers.LSTM(32)(embedded_text)\n",
    "\n",
    "# input 2\n",
    "question_input = Input(shape=(None,), dtype='int32', name='question')\n",
    "embedded_question = layers.Embedding(question_vocab_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "# inputs are merged via concatination into dense layer\n",
    "concatinated = layers.concatenate([encoded_text, encoded_question], axis=-1)\n",
    "answer = layers.Dense(answer_vocab_size, activation='softmax')(concatinated)\n",
    "model = Model([text_input, question_input], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model on random data\n",
    "import numpy as np\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocab_size, size=(num_samples, max_length))\n",
    "question = np.random.randint(1, question_vocab_size, size=(num_samples, max_length))\n",
    "\n",
    "answers = np.zeros((num_samples, answer_vocab_size))\n",
    "for answer in answers:\n",
    "  answer[np.random.randint(answer_vocab_size)] = 1\n",
    "\n",
    "# mapping data to multiple inputs:\n",
    "# 1. can use a list of np arrays in the appropriate order\n",
    "# OR\n",
    "# 2. can use a dictionary mapping an array to each input\n",
    "\n",
    "# 1\n",
    "#model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "\n",
    "# 2\n",
    "model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-output Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build multi-input model (to predict user attributes from social media posts)\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "vocab_size = 50_000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(vocab_size, 256)(posts_input)\n",
    "\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "# multiple outputs\n",
    "age_prediction = layers.Dense(1, name='age')(x)\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])\n",
    "\n",
    "# combine multi-output loss functions into one loss function\n",
    "# default is to sum each loss, or a linear combination with weights\n",
    "# weights help when different losses use different scales\n",
    "# (could use lists or dictionary)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss={'age': 'mse', 'income': 'categorical_crossentropy', 'gender': 'binary_crossentropy'},\n",
    "              loss_weights={'age': 0.25, 'income': 1., 'gender': 10.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model on random data\n",
    "import numpy as np\n",
    "\n",
    "# (these must be tuned for model to work.\n",
    "# e.g. if post size is too small, convolutions are too large)\n",
    "num_samples = 100\n",
    "post_size = 1000\n",
    "\n",
    "posts = np.random.randint(1, vocab_size, size=(num_samples, post_size))\n",
    "age_targets = np.random.randint(10, 100, size=num_samples)\n",
    "income_targets = np.random.randint(0, num_income_groups, size=num_samples)\n",
    "income_targets = np.eye(num_income_groups)[income_targets]\n",
    "gender_targets = np.random.randint(0, 2, size=num_samples)\n",
    "\n",
    "model.fit(posts,\n",
    "          {'age': age_targets,'income': income_targets, 'gender': gender_targets},\n",
    "          epochs=10, batch_size=64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "56812fdf969ac077eeaf2ef088cf4d7847f3481c325e30630107ab1a17355ea1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
