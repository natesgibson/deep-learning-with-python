{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this script I used some of the 2nd edition code found here:\n",
    "# https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/chapter12_part03_neural-style-transfer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate image height based on set image width\n",
    "from tensorflow import keras\n",
    "\n",
    "base_image_path = keras.utils.get_file('sf.jpg', origin='https://img-datasets.s3.amazonaws.com/sf.jpg')\n",
    "style_image_path = keras.utils.get_file('starry_night.jpg', origin = 'https://img-datasets.s3.amazonaws.com/starry_night.jpg')\n",
    "\n",
    "width, height = keras.utils.load_img(base_image_path).size\n",
    "img_height = 400\n",
    "img_width = round(width * img_height / height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxillary functions\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = keras.utils.load_img(image_path, target_size=(img_height, img_width))\n",
    "    img = keras.utils.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = keras.applications.vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# reverses processes done in vgg19.preprocess_input()\n",
    "def deprocess_image(img):\n",
    "    img = img.reshape((img_height, img_width, 3))\n",
    "    # zero-centering via removing the mean pizel value from ImageNet\n",
    "    img[:, :, 0] += 103.939\n",
    "    img[:, :, 1] += 116.779\n",
    "    img[:, :, 2] += 123.68\n",
    "    # bgr to rgb\n",
    "    img = img[:, :, ::-1]\n",
    "    img = np.clip(img, 0, 255).astype('uint8')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pretrained VGG19 network\n",
    "model = keras.applications.vgg19.VGG19(weights='imagenet', include_top=False)\n",
    "\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "feature_extractor = keras.Model(inputs=model.inputs, outputs=outputs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss functions\n",
    "import tensorflow as tf\n",
    "\n",
    "def content_loss(base, combination):\n",
    "    return tf.reduce_sum(tf.square(combination - base))\n",
    "\n",
    "def style_loss(style, combination):\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_height * img_width\n",
    "    return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))\n",
    "\n",
    "def gram_matrix(x):\n",
    "    x = tf.transpose(x, (2, 0, 1))\n",
    "    features = tf.reshape(x, (tf.shape(x)[0], -1))\n",
    "    return tf.matmul(features, tf.transpose(features))\n",
    "\n",
    "def total_variation_loss(x):\n",
    "    a = tf.square(x[:, :img_height - 1, :img_width - 1, :] -\n",
    "                x[:, 1:, :img_width - 1, :])\n",
    "    b = tf.square(x[:, :img_height - 1, :img_width - 1, :] -\n",
    "                 x[:, :img_height - 1, 1:, :])\n",
    "    return tf.reduce_sum(tf.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine loss functions into final loss\n",
    "content_weight = 2.5e-8\n",
    "style_weight = 1e-6\n",
    "total_variation_weight = 1e-6\n",
    "\n",
    "content_layer_name = 'block5_conv2'\n",
    "style_layer_names = ['block1_conv1',\n",
    "                     'block2_conv1',\n",
    "                     'block3_conv1',\n",
    "                     'block4_conv1',\n",
    "                     'block5_conv1']\n",
    "\n",
    "style_weight /= len(style_layer_names)\n",
    "\n",
    "def compute_loss(combination, base, style):\n",
    "    input_tensor = tf.concat([base, style, combination], axis=0)\n",
    "    features = feature_extractor(input_tensor)\n",
    "    \n",
    "    loss = tf.zeros(shape=())\n",
    "\n",
    "    # add content loss\n",
    "    layer_features = features[content_layer_name]\n",
    "    base_features = layer_features[0, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    loss = loss + (content_weight * content_loss(base_features,\n",
    "                                        combination_features))\n",
    "\n",
    "    # add style loss\n",
    "    for layer_name in style_layer_names:\n",
    "        layer_features = features[layer_name]\n",
    "        style_features = layer_features[1, :, :, :]\n",
    "        combination_features = layer_features[2, :, :, :]\n",
    "        loss = loss + (style_weight * style_loss(style_features,\n",
    "                                                combination_features))\n",
    "        \n",
    "    # add total variation loss\n",
    "    loss = loss + (total_variation_weight * total_variation_loss(combination))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create combination image via gradient-descent\n",
    "import time\n",
    "\n",
    "@tf.function\n",
    "def compute_loss_and_grads(combination, base, style):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = compute_loss(combination, base, style)\n",
    "    grads = tape.gradient(loss, combination)\n",
    "    return loss, grads\n",
    "    \n",
    "optimizer = keras.optimizers.legacy.SGD(\n",
    "    keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate = 100.0, decay_steps=100, decay_rate=0.96\n",
    "    )\n",
    ")\n",
    "\n",
    "base = preprocess_image(base_image_path)\n",
    "style = preprocess_image(style_image_path)\n",
    "combination = tf.Variable(preprocess_image(base_image_path))\n",
    "\n",
    "iterations = 200\n",
    "for i in range(1, iterations + 1):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    loss, grads = compute_loss_and_grads(combination, base, style)\n",
    "    optimizer.apply_gradients([(grads, combination)])\n",
    "    \n",
    "    if i % 10 == 0 or i == 1:\n",
    "        img = deprocess_image(combination.numpy())\n",
    "        fname = f'combination_image_at_iteration_{i}.png'\n",
    "        keras.utils.save_img(fname, img)\n",
    "        \n",
    "    print(f'Iteration {i}: loss={loss:.2f}, time={(time.time() - start_time):.1f}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
